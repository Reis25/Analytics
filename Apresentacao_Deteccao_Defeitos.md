# üçæ Detec√ß√£o de Defeitos em Garrafas de Coca-Cola
## An√°lise T√©cnica do Sistema de Vis√£o Computacional

---

## üìä Vis√£o Geral do Projeto

**Objetivo:** Detectar automaticamente defeitos em garrafas de Coca-Cola usando Deep Learning

**Problema:** Classifica√ß√£o Multi-Label
- Uma garrafa pode ter m√∫ltiplos defeitos simult√¢neos
- 8 tipos de defeitos poss√≠veis
- Dataset real de linha de produ√ß√£o

**Dataset:** 141 imagens (120x160 pixels, RGB)

---

## üéØ Tipos de Defeitos Detectados

### 8 Classes de Defeitos:

1. **CONTENT_HIGH** - N√≠vel de l√≠quido acima do padr√£o
2. **CONTENT_LOW** - N√≠vel de l√≠quido abaixo do padr√£o
3. **COVER_NONE** - Tampa ausente
4. **BOTTLE_SMASHED** - Garrafa quebrada/amassada
5. **LABEL_WHITE** - R√≥tulo em branco/sem impress√£o
6. **LABEL_MISPLACED** - R√≥tulo mal posicionado
7. **LABEL_NONE** - R√≥tulo ausente
8. **BOTTLE_NONE** - Garrafa ausente

> **Caracter√≠stica especial:** Uma √∫nica garrafa pode ter v√°rios defeitos (ex: tampa ausente + r√≥tulo mal posicionado)

---

## üñºÔ∏è Processamento de Imagens

### T√©cnicas Aplicadas:

**1. Redimensionamento**
- Dimens√µes padronizadas: 120x160 pixels
- Algoritmo LANCZOS para preservar qualidade
- Mant√©m propor√ß√£o original das garrafas

**2. Normaliza√ß√£o**
- Pixels convertidos para escala 0-1 (divis√£o por 255)
- Facilita converg√™ncia do modelo
- Padr√£o em redes neurais

**3. Multi-Hot Encoding**
- Converte labels para formato bin√°rio
- Permite m√∫ltiplos defeitos simult√¢neos
- Exemplo: [1, 0, 1, 0, 0, 0, 0, 0] = defeitos 1 e 3 presentes

---

## üîÑ Data Augmentation

### Por que usar?
Dataset pequeno (141 imagens) ‚Üí Risco de overfitting

### Transforma√ß√µes Aplicadas (apenas no treino):

| T√©cnica | Configura√ß√£o | Justificativa |
|---------|--------------|---------------|
| **Rota√ß√£o** | ¬±10¬∞ | Limitado - garrafas s√£o verticais |
| **Deslocamento** | ¬±10% (H/V) | Simula posi√ß√µes variadas na esteira |
| **Zoom** | ¬±10% | Simula diferentes dist√¢ncias da c√¢mera |
| **Brilho** | 80-120% | Simula varia√ß√µes de ilumina√ß√£o |
| **Flip Horizontal** | ‚ùå DESATIVADO | Garrafas n√£o devem ser espelhadas |

> **Resultado:** Aumenta artificialmente o dataset, melhorando generaliza√ß√£o

---

## üìÇ Divis√£o dos Dados

### Estrat√©gia de Separa√ß√£o:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Dataset Total: 141 imagens     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚Üì              ‚Üì          ‚Üì
  Treino         Valida√ß√£o   Teste
   64%            16%         20%
(90 imgs)      (23 imgs)   (28 imgs)
    ‚Üì
Com Data
Augmentation
```

**Estratifica√ß√£o:** Mant√©m propor√ß√£o de classes em cada conjunto

**Valida√ß√£o:** Monitora performance durante treinamento

**Teste:** Avalia√ß√£o final imparcial (nunca visto pelo modelo)

---

## üß† Modelo 1: CNN Custom (Baseline)

### Arquitetura Simples mas Eficaz

```
INPUT (120x160x3)
    ‚Üì
[Bloco Conv 1] ‚Üí 32 filtros ‚Üí MaxPool ‚Üí Dropout(0.25)
    ‚Üì
[Bloco Conv 2] ‚Üí 64 filtros ‚Üí MaxPool ‚Üí Dropout(0.25)
    ‚Üì
[Bloco Conv 3] ‚Üí 128 filtros ‚Üí MaxPool ‚Üí Dropout(0.30)
    ‚Üì
Flatten ‚Üí Dense(256) ‚Üí Dropout(0.5)
    ‚Üì
OUTPUT: Dense(8, sigmoid)
```

**Caracter√≠sticas:**
- Totalmente trein√°vel desde zero
- ~256k par√¢metros
- Boa baseline para compara√ß√£o
- R√°pido para treinar

**Vantagem:** Adaptado especificamente para garrafas

---

## üöÄ Modelo 2: ResNet50 (Transfer Learning)

### Aproveitando Conhecimento Pr√©-Treinado

```
ResNet50 (ImageNet)
[23M par√¢metros CONGELADOS]
    ‚Üì
GlobalAveragePooling2D
    ‚Üì
Dense(256, relu)
    ‚Üì
Dropout(0.5)
    ‚Üì
OUTPUT: Dense(8, sigmoid)
```

**O que √© Transfer Learning?**
- Usa rede treinada em milh√µes de imagens
- Camadas iniciais detectam features gen√©ricas (bordas, texturas)
- Apenas √∫ltimas camadas s√£o retreinadas para defeitos

**Vantagens:**
- Excelente para datasets pequenos
- Aprende r√°pido (pesos pr√©-treinados)
- Alta precis√£o

**Desvantagens:**
- ~25M par√¢metros (pesado)
- Mais lento para infer√™ncia

---

## üì± Modelo 3: MobileNetV2 (Leve e R√°pido)

### Otimizado para Dispositivos M√≥veis

```
MobileNetV2 (ImageNet)
[2.2M par√¢metros CONGELADOS]
    ‚Üì
GlobalAveragePooling2D
    ‚Üì
Dense(128, relu)  ‚Üê Menor que ResNet
    ‚Üì
Dropout(0.4)
    ‚Üì
OUTPUT: Dense(8, sigmoid)
```

**Por que MobileNet?**
- Arquitetura eficiente (depthwise separable convolutions)
- 10x mais leve que ResNet50
- Ideal para implanta√ß√£o em produ√ß√£o

**Trade-off:**
- Performance ligeiramente inferior
- Muito mais r√°pido e leve
- Pode rodar em dispositivos embarcados

---

## ‚öôÔ∏è Configura√ß√£o de Treinamento

### Hiperpar√¢metros Principais:

| Par√¢metro | CNN Custom | ResNet50/MobileNet |
|-----------|------------|-------------------|
| **Loss** | Binary Crossentropy | Binary Crossentropy |
| **Optimizer** | Adam (lr=0.001) | Adam (lr=0.0001) |
| **Ativa√ß√£o Final** | Sigmoid | Sigmoid |
| **√âpocas M√°ximas** | 100 | 100 |
| **Batch Size** | 16 | 16 |

### Por que Binary Crossentropy?
- Apropriado para classifica√ß√£o multi-label
- Cada classe √© tratada independentemente
- Diferente de Categorical Crossentropy (exclusivo)

### Por que Sigmoid (n√£o Softmax)?
- Sigmoid: Cada sa√≠da entre 0-1 independentemente
- Softmax: Soma das sa√≠das = 1 (exclus√£o m√∫tua)
- Multi-label precisa de predi√ß√µes independentes

---

## üéöÔ∏è Callbacks Inteligentes

### 1. Early Stopping
```python
EarlyStopping(
    monitor='val_loss',
    patience=15,
    restore_best_weights=True
)
```
**Fun√ß√£o:** Para treinamento quando n√£o h√° melhora
- Monitora loss de valida√ß√£o
- Espera 15 √©pocas antes de parar
- Restaura melhores pesos automaticamente
- **Evita overfitting**

### 2. ReduceLROnPlateau
```python
ReduceLROnPlateau(
    factor=0.5,
    patience=7,
    min_lr=1e-7
)
```
**Fun√ß√£o:** Ajusta learning rate dinamicamente
- Reduz LR em 50% quando estagna
- Ajuda modelo a "afinar" predi√ß√µes
- Melhora converg√™ncia

---

## üìà M√©tricas de Avalia√ß√£o

### M√©tricas Multi-Label Espec√≠ficas:

**1. Accuracy (Acur√°cia)**
- Porcentagem de predi√ß√µes totalmente corretas
- M√©trica b√°sica de performance

**2. AUC (Area Under Curve)**
- √Årea sob curva ROC
- Robusta para classes desbalanceadas
- **M√©trica principal para compara√ß√£o**
- Varia de 0 a 1 (quanto maior, melhor)

**3. Hamming Loss**
- Fra√ß√£o de labels incorretas
- Espec√≠fico para multi-label
- Quanto menor, melhor
- Exemplo: 2 erros em 8 labels = 0.25

**4. Precision & Recall (por classe)**
- Precision: Das predi√ß√µes positivas, quantas est√£o corretas?
- Recall: Dos defeitos reais, quantos foram detectados?

---

## üîç An√°lise Explorat√≥ria dos Dados

### Insights Descobertos:

**Distribui√ß√£o de Defeitos:**
- Classes desbalanceadas (alguns defeitos mais raros)
- Necessidade de m√©tricas robustas (AUC)

**Defeitos por Garrafa:**
- M√©dia de defeitos por imagem
- Algumas garrafas sem defeitos
- Outras com m√∫ltiplos defeitos simult√¢neos

**Visualiza√ß√µes:**
- Amostras de cada tipo de defeito
- Gr√°ficos de distribui√ß√£o
- Matriz de co-ocorr√™ncia de defeitos

> **Import√¢ncia:** Entender dados antes de modelar

---

## üèÜ Compara√ß√£o dos Modelos

### Tabela Comparativa:

| Modelo | Par√¢metros | AUC | Hamming Loss | Velocidade | Uso |
|--------|------------|-----|--------------|------------|-----|
| **CNN Custom** | 256k | ‚≠ê‚≠ê‚≠ê | M√©dio | ‚ö°‚ö°‚ö° | Baseline/Prototipagem |
| **ResNet50** | 25M | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Menor | ‚ö° | Alta precis√£o |
| **MobileNetV2** | 3M | ‚≠ê‚≠ê‚≠ê‚≠ê | Baixo | ‚ö°‚ö°‚ö° | Produ√ß√£o/Embarcados |

### Recomenda√ß√µes:

**Para Laborat√≥rio/Pesquisa:** ResNet50
- M√°xima precis√£o
- Recursos computacionais dispon√≠veis

**Para Produ√ß√£o/Linha de Fabrica√ß√£o:** MobileNetV2
- √ìtimo balan√ßo precis√£o/velocidade
- Pode rodar em hardware limitado
- Custo-benef√≠cio superior

**Para Prototipagem R√°pida:** CNN Custom
- R√°pido para treinar e ajustar
- Entender viabilidade do problema

---

## üõ†Ô∏è Stack Tecnol√≥gico

### Bibliotecas Utilizadas:

**Deep Learning:**
- `TensorFlow/Keras` - Framework principal
- `keras.applications` - Modelos pr√©-treinados
- `keras.callbacks` - Controle de treinamento

**Processamento de Dados:**
- `NumPy` - Opera√ß√µes matriciais
- `Pandas` - Manipula√ß√£o de dataframes
- `PIL` - Processamento de imagens

**An√°lise e Visualiza√ß√£o:**
- `Matplotlib` - Gr√°ficos
- `Seaborn` - Visualiza√ß√µes estat√≠sticas
- `scikit-learn` - M√©tricas e divis√£o de dados

---

## ‚ú® Destaques T√©cnicos

### Decis√µes Importantes de Projeto:

**1. Multi-Label em vez de Multi-Class**
- Permite detec√ß√£o de m√∫ltiplos defeitos
- Mais realista para inspe√ß√£o industrial
- Sigmoid + Binary Crossentropy

**2. Transfer Learning**
- Compensa dataset pequeno (141 imagens)
- Aproveita conhecimento de milh√µes de imagens
- Base congelada, apenas cabe√ßa trein√°vel

**3. Adapta√ß√µes Espec√≠ficas para Garrafas**
- Sem flip horizontal (mant√©m orienta√ß√£o)
- Rota√ß√£o limitada (garrafas s√£o verticais)
- Augmentation controlado

**4. Data Augmentation Essencial**
- Aumenta dataset artificialmente
- Previne overfitting
- Melhora generaliza√ß√£o

---

## üéØ Resultados e Conclus√µes

### Pontos Fortes do Sistema:

‚úÖ Detecta m√∫ltiplos defeitos simult√¢neos
‚úÖ Tr√™s op√ß√µes de modelo (precis√£o vs. velocidade)
‚úÖ Robusto a varia√ß√µes de ilumina√ß√£o e posi√ß√£o
‚úÖ Transfer Learning eficaz para dataset pequeno
‚úÖ M√©tricas adequadas para avalia√ß√£o multi-label

### Limita√ß√µes:

‚ö†Ô∏è Dataset pequeno (141 imagens)
‚ö†Ô∏è Poss√≠vel bias em classes raras
‚ö†Ô∏è Depende de qualidade das imagens de entrada

### Pr√≥ximos Passos:

1. **Coletar mais dados** - Expandir dataset
2. **Fine-tuning** - Destravar camadas da base
3. **Ensemble** - Combinar predi√ß√µes dos 3 modelos
4. **Threshold Optimization** - Ajustar por classe
5. **Deploy** - Integrar em linha de produ√ß√£o

---

## üí° Aplica√ß√µes Pr√°ticas

### Cen√°rios de Uso:

**1. Linha de Produ√ß√£o**
- Inspe√ß√£o autom√°tica 24/7
- Redu√ß√£o de falhas humanas
- Aumento de throughput

**2. Controle de Qualidade**
- Rastreamento de defeitos por lote
- An√°lise de tend√™ncias
- Melhoria cont√≠nua de processos

**3. Alertas em Tempo Real**
- Notifica√ß√£o imediata de defeitos
- Interven√ß√£o r√°pida
- Redu√ß√£o de desperd√≠cio

**4. Relat√≥rios Automatizados**
- Estat√≠sticas de produ√ß√£o
- KPIs de qualidade
- Auditoria e compliance

---

## üìö Refer√™ncias e Recursos

### Arquiteturas Utilizadas:

- **ResNet50:** He et al., 2015 - "Deep Residual Learning for Image Recognition"
- **MobileNetV2:** Sandler et al., 2018 - "Inverted Residuals and Linear Bottlenecks"

### Conceitos Aplicados:

- Transfer Learning
- Data Augmentation
- Multi-Label Classification
- Binary Cross-Entropy Loss
- Early Stopping & Learning Rate Scheduling

### Dataset:

- Ground Truth: `bottles_ground_truth.csv`
- Imagens reais de linha de produ√ß√£o
- 8 categorias de defeitos anotadas

---

## üôè Obrigado!

### Resumo Final:

Este projeto demonstra como **Deep Learning** pode ser aplicado eficazmente em **inspe√ß√£o industrial**, mesmo com **datasets limitados**, usando t√©cnicas como:

- üîÑ Data Augmentation
- üß† Transfer Learning
- üìä Classifica√ß√£o Multi-Label
- ‚öñÔ∏è Balan√ßo entre precis√£o e efici√™ncia

**Resultado:** Sistema robusto e pr√°tico para detec√ß√£o autom√°tica de defeitos em garrafas

---

### Contato e Perguntas

**Documenta√ß√£o Completa:** `Deteccao_Defeitos_Garrafas_CocaCola.ipynb`

**Modelos Dispon√≠veis:**
- CNN Custom (baseline)
- ResNet50 (m√°xima precis√£o)
- MobileNetV2 (produ√ß√£o)

---
