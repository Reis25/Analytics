# ğŸ¾ DetecÃ§Ã£o de Defeitos em Garrafas de Coca-Cola
## AnÃ¡lise TÃ©cnica do Sistema de VisÃ£o Computacional

---

## ğŸ¤– Machine Learning vs Deep Learning

### O que Ã© Machine Learning?

**Machine Learning (ML)** Ã© um subcampo da InteligÃªncia Artificial que permite aos computadores aprenderem com dados sem serem explicitamente programados.

**CaracterÃ­sticas:**
- Requer engenharia manual de features (caracterÃ­sticas)
- Algoritmos clÃ¡ssicos: Decision Trees, SVM, Random Forest, Naive Bayes
- Humano define quais caracterÃ­sticas sÃ£o importantes
- Bom para dados estruturados/tabulares

**Exemplo em inspeÃ§Ã£o de qualidade:**
```
Humano define: "Cor da tampa", "Altura do lÃ­quido", "PresenÃ§a de rÃ³tulo"
â†“
Algoritmo aprende: "Se altura < 10cm E cor_tampa = branco â†’ Defeito"
```

### O que Ã© Deep Learning?

**Deep Learning (DL)** Ã© um subconjunto do Machine Learning baseado em redes neurais artificiais profundas (mÃºltiplas camadas).

**CaracterÃ­sticas:**
- **Aprendizado automÃ¡tico de features** (nÃ£o precisa de engenharia manual)
- Arquiteturas em camadas (input â†’ camadas ocultas â†’ output)
- Excelente para dados nÃ£o estruturados (imagens, texto, Ã¡udio)
- Requer mais dados e poder computacional

**Exemplo em inspeÃ§Ã£o de qualidade:**
```
Imagem da garrafa â†’ [Rede Neural Profunda] â†’ Defeitos detectados
                      â†‘
              (aprende sozinha a identificar:
               bordas, texturas, formas, padrÃµes)
```

### ComparaÃ§Ã£o Lado a Lado:

| Aspecto | Machine Learning | Deep Learning |
|---------|------------------|---------------|
| **Features** | Manual (engenharia de features) | AutomÃ¡tico (aprende sozinho) |
| **Arquitetura** | Algoritmos simples | Redes neurais profundas |
| **Dados necessÃ¡rios** | Poucos a mÃ©dios | Muitos |
| **Hardware** | CPU suficiente | GPU recomendado |
| **Interpretabilidade** | Alta | Baixa ("caixa preta") |
| **Performance em imagens** | Limitada | Excelente |
| **Tempo de desenvolvimento** | RÃ¡pido (mas requer expertise) | Mais lento (mas automatizado) |

### Por que Deep Learning para DetecÃ§Ã£o de Defeitos?

âœ… **Complexidade Visual:** Defeitos em garrafas envolvem padrÃµes visuais complexos
âœ… **MÃºltiplas VariaÃ§Ãµes:** IluminaÃ§Ã£o, Ã¢ngulo, posiÃ§Ã£o variam constantemente
âœ… **Features HierÃ¡rquicas:** DL aprende automaticamente desde bordas bÃ¡sicas atÃ© conceitos complexos
âœ… **Estado da Arte:** CNNs sÃ£o superiores em visÃ£o computacional
âœ… **Transfer Learning:** Compensa datasets pequenos

**Neste projeto:** Usamos **Deep Learning** (CNNs) porque:
- Imagens tÃªm alta dimensionalidade (120Ã—160Ã—3 = 57,600 valores)
- Defeitos visuais sÃ£o difÃ­ceis de descrever manualmente
- Transfer Learning permite usar conhecimento prÃ©-existente
- CNNs sÃ£o o estado da arte em inspeÃ§Ã£o visual industrial

---

## ğŸ“Š VisÃ£o Geral do Projeto

**Objetivo:** Detectar automaticamente defeitos em garrafas de Coca-Cola usando Deep Learning

**Problema:** ClassificaÃ§Ã£o Multi-Label
- Uma garrafa pode ter mÃºltiplos defeitos simultÃ¢neos
- 8 tipos de defeitos possÃ­veis
- Dataset real de linha de produÃ§Ã£o

**Dataset:** 141 imagens (120x160 pixels, RGB)

---

## ğŸ¯ Tipos de Defeitos Detectados

### 8 Classes de Defeitos:

1. **CONTENT_HIGH** - NÃ­vel de lÃ­quido acima do padrÃ£o
2. **CONTENT_LOW** - NÃ­vel de lÃ­quido abaixo do padrÃ£o
3. **COVER_NONE** - Tampa ausente
4. **BOTTLE_SMASHED** - Garrafa quebrada/amassada
5. **LABEL_WHITE** - RÃ³tulo em branco/sem impressÃ£o
6. **LABEL_MISPLACED** - RÃ³tulo mal posicionado
7. **LABEL_NONE** - RÃ³tulo ausente
8. **BOTTLE_NONE** - Garrafa ausente

> **CaracterÃ­stica especial:** Uma Ãºnica garrafa pode ter vÃ¡rios defeitos (ex: tampa ausente + rÃ³tulo mal posicionado)

---

## ğŸ–¼ï¸ Processamento de Imagens

### TÃ©cnicas Aplicadas:

**1. Redimensionamento**
- DimensÃµes padronizadas: 120x160 pixels
- Algoritmo LANCZOS para preservar qualidade
- MantÃ©m proporÃ§Ã£o original das garrafas

**2. NormalizaÃ§Ã£o**
- Pixels convertidos para escala 0-1 (divisÃ£o por 255)
- Facilita convergÃªncia do modelo
- PadrÃ£o em redes neurais

**3. Multi-Hot Encoding**
- Converte labels para formato binÃ¡rio
- Permite mÃºltiplos defeitos simultÃ¢neos
- Exemplo: [1, 0, 1, 0, 0, 0, 0, 0] = defeitos 1 e 3 presentes

---

## ğŸ”„ Data Augmentation

### Por que usar?
Dataset pequeno (141 imagens) â†’ Risco de overfitting

### TransformaÃ§Ãµes Aplicadas (apenas no treino):

| TÃ©cnica | ConfiguraÃ§Ã£o | Justificativa |
|---------|--------------|---------------|
| **RotaÃ§Ã£o** | Â±10Â° | Limitado - garrafas sÃ£o verticais |
| **Deslocamento** | Â±10% (H/V) | Simula posiÃ§Ãµes variadas na esteira |
| **Zoom** | Â±10% | Simula diferentes distÃ¢ncias da cÃ¢mera |
| **Brilho** | 80-120% | Simula variaÃ§Ãµes de iluminaÃ§Ã£o |
| **Flip Horizontal** | âŒ DESATIVADO | Garrafas nÃ£o devem ser espelhadas |

> **Resultado:** Aumenta artificialmente o dataset, melhorando generalizaÃ§Ã£o

---

## ğŸ“‚ DivisÃ£o dos Dados

### EstratÃ©gia de SeparaÃ§Ã£o:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dataset Total: 141 imagens     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“              â†“          â†“
  Treino         ValidaÃ§Ã£o   Teste
   64%            16%         20%
(90 imgs)      (23 imgs)   (28 imgs)
    â†“
Com Data
Augmentation
```

**EstratificaÃ§Ã£o:** MantÃ©m proporÃ§Ã£o de classes em cada conjunto

**ValidaÃ§Ã£o:** Monitora performance durante treinamento

**Teste:** AvaliaÃ§Ã£o final imparcial (nunca visto pelo modelo)

---

## ğŸ“ Fundamentos MatemÃ¡ticos: Redes Neurais Convolucionais (CNN)

### O que Ã© uma CNN?

**Convolutional Neural Network (CNN)** Ã© uma arquitetura de rede neural especializada em processar dados com estrutura de grade (como imagens).

### OperaÃ§Ãµes MatemÃ¡ticas Principais:

#### 1. **ConvoluÃ§Ã£o 2D**

A operaÃ§Ã£o fundamental que extrai features da imagem:

```
SaÃ­da[i,j] = Î£ Î£ Entrada[i+m, j+n] Ã— Kernel[m,n] + bias
             m n
```

**Onde:**
- `Entrada`: Imagem ou mapa de features (HÃ—WÃ—C)
- `Kernel/Filtro`: Matriz de pesos aprendÃ­veis (3Ã—3, 5Ã—5, etc.)
- `SaÃ­da`: Feature map resultante
- `Stride`: Passo do filtro (geralmente 1)
- `Padding`: Preenchimento nas bordas

**Exemplo visual:**
```
Imagem 5Ã—5          Filtro 3Ã—3         Feature Map 3Ã—3
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”
â”‚1 2 3 4 5â”‚         â”‚1 0 1â”‚            â”‚ 12  â”‚
â”‚2 3 4 5 6â”‚    *    â”‚0 1 0â”‚    =       â”‚ 16  â”‚
â”‚3 4 5 6 7â”‚         â”‚1 0 1â”‚            â”‚ 20  â”‚
â”‚4 5 6 7 8â”‚         â””â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”˜
â”‚5 6 7 8 9â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Por que convoluÃ§Ã£o?**
- Detecta padrÃµes locais (bordas, texturas)
- Compartilhamento de parÃ¢metros (mesmo filtro em toda imagem)
- InvariÃ¢ncia translacional (detecta padrÃ£o em qualquer posiÃ§Ã£o)

#### 2. **FunÃ§Ã£o de AtivaÃ§Ã£o (ReLU)**

Introduz nÃ£o-linearidade no modelo:

```
ReLU(x) = max(0, x) = { x,  se x > 0
                      { 0,  se x â‰¤ 0
```

**Por que ReLU?**
- Simples e eficiente computacionalmente
- Evita vanishing gradient
- Esparsidade (muitos neurÃ´nios "desligados")

#### 3. **Max Pooling**

Reduz dimensionalidade preservando features importantes:

```
Para cada janela 2Ã—2, pega o valor mÃ¡ximo:

â”Œâ”€â”€â”€â”€â”         â”Œâ”€â”€â”
â”‚1 3â”‚         â”‚4 â”‚
â”‚2 4â”‚    â†’    â””â”€â”€â”˜
â””â”€â”€â”€â”€â”˜
```

**Matematicamente:**
```
SaÃ­da[i,j] = max{ Entrada[2i+m, 2j+n] | m,n âˆˆ {0,1} }
```

**BenefÃ­cios:**
- Reduz parÃ¢metros (evita overfitting)
- InvariÃ¢ncia a pequenos deslocamentos
- MantÃ©m features mais salientes

#### 4. **Dropout**

RegularizaÃ§Ã£o que desativa neurÃ´nios aleatoriamente durante treino:

```
Durante treino (p = 0.5):
SaÃ­da = { 0,        com probabilidade p
        { x/(1-p),  com probabilidade 1-p

Durante teste:
SaÃ­da = x  (todos neurÃ´nios ativos)
```

**Por que Dropout?**
- Previne overfitting
- Cria ensemble implÃ­cito de redes
- ForÃ§a redundÃ¢ncia nas representaÃ§Ãµes

#### 5. **Camada Densa (Fully Connected)**

NeurÃ´nio clÃ¡ssico conectado a todos inputs:

```
y = Ïƒ(WÂ·x + b)

Onde:
- x: vetor de entrada (n dimensÃµes)
- W: matriz de pesos (mÃ—n)
- b: vetor de bias (m dimensÃµes)
- Ïƒ: funÃ§Ã£o de ativaÃ§Ã£o
- y: saÃ­da (m dimensÃµes)
```

**Para classificaÃ§Ã£o multi-label:**
```
Output[k] = sigmoid(Î£ w[k,i] Ã— x[i] + b[k])
                    i
```

#### 6. **Sigmoid (AtivaÃ§Ã£o Final)**

Para classificaÃ§Ã£o multi-label (prediÃ§Ãµes independentes):

```
Ïƒ(z) = 1 / (1 + e^(-z))

Propriedades:
- SaÃ­da entre 0 e 1
- Cada classe Ã© independente
- Threshold: y > 0.5 â†’ classe presente
```

**DiferenÃ§a do Softmax:**
```
Softmax (multi-class):  P(y=k) = e^(z_k) / Î£ e^(z_i)  â†’ Soma = 1
Sigmoid (multi-label):  P(y_k) = 1/(1+e^(-z_k))      â†’ Independentes
```

---

## ğŸ§  Modelo 1: CNN Custom (Baseline)

### Resumo MatemÃ¡tico da Arquitetura

**Fluxo de transformaÃ§Ãµes dimensionais:**

```
INPUT: X âˆˆ â„^(120Ã—160Ã—3)
   â†“
BLOCO 1:
  Conv2D(32):  Xâ‚ = ReLU(Wâ‚ * X + bâ‚)     â†’ (120Ã—160Ã—32)
  Conv2D(32):  Xâ‚‚ = ReLU(Wâ‚‚ * Xâ‚ + bâ‚‚)    â†’ (120Ã—160Ã—32)
  MaxPool(2Ã—2): Xâ‚ƒ = MaxPool(Xâ‚‚)          â†’ (60Ã—80Ã—32)
  Dropout(0.25): Xâ‚„ = Dropout(Xâ‚ƒ, p=0.25) â†’ (60Ã—80Ã—32)
   â†“
BLOCO 2:
  Conv2D(64):  Xâ‚… = ReLU(Wâ‚… * Xâ‚„ + bâ‚…)    â†’ (60Ã—80Ã—64)
  Conv2D(64):  Xâ‚† = ReLU(Wâ‚† * Xâ‚… + bâ‚†)    â†’ (60Ã—80Ã—64)
  MaxPool(2Ã—2): Xâ‚‡ = MaxPool(Xâ‚†)          â†’ (30Ã—40Ã—64)
  Dropout(0.25): Xâ‚ˆ = Dropout(Xâ‚‡, p=0.25) â†’ (30Ã—40Ã—64)
   â†“
BLOCO 3:
  Conv2D(128): Xâ‚‰ = ReLU(Wâ‚‰ * Xâ‚ˆ + bâ‚‰)    â†’ (30Ã—40Ã—128)
  MaxPool(2Ã—2): Xâ‚â‚€ = MaxPool(Xâ‚‰)         â†’ (15Ã—20Ã—128)
  Dropout(0.3):  Xâ‚â‚ = Dropout(Xâ‚â‚€, p=0.3) â†’ (15Ã—20Ã—128)
   â†“
CLASSIFICADOR:
  Flatten:     Xâ‚â‚‚ = Flatten(Xâ‚â‚)          â†’ (38400,)
  Dense(256):  Xâ‚â‚ƒ = ReLU(Wâ‚â‚ƒÂ·Xâ‚â‚‚ + bâ‚â‚ƒ)  â†’ (256,)
  Dropout(0.5): Xâ‚â‚„ = Dropout(Xâ‚â‚ƒ, p=0.5) â†’ (256,)
  Dense(8):    Å· = Ïƒ(Wâ‚â‚„Â·Xâ‚â‚„ + bâ‚â‚„)       â†’ (8,)
   â†“
OUTPUT: Å· âˆˆ [0,1]^8  (probabilidades por classe)
```

**FunÃ§Ã£o de perda (Binary Cross-Entropy):**

```
L = -1/N Î£ Î£ [y_ikÂ·log(Å·_ik) + (1-y_ik)Â·log(1-Å·_ik)]
        i k

Onde:
- N: nÃºmero de amostras
- k: classe (8 classes)
- y_ik: label real (0 ou 1)
- Å·_ik: prediÃ§Ã£o (entre 0 e 1)
```

**OtimizaÃ§Ã£o (Adam):**

```
m_t = Î²â‚Â·m_{t-1} + (1-Î²â‚)Â·âˆ‡L        (primeiro momento)
v_t = Î²â‚‚Â·v_{t-1} + (1-Î²â‚‚)Â·(âˆ‡L)Â²    (segundo momento)
Î¸_t = Î¸_{t-1} - Î±Â·mÌ‚_t/âˆš(vÌ‚_t + Îµ)  (atualizaÃ§Ã£o)

Onde:
- Î± = 0.001 (learning rate)
- Î²â‚ = 0.9, Î²â‚‚ = 0.999 (padrÃµes Adam)
- Îµ = 10â»â¸ (estabilidade numÃ©rica)
```

**NÃºmero total de parÃ¢metros:**
```
ConvoluÃ§Ãµes: ~150k parÃ¢metros
Dense layers: ~100k parÃ¢metros
Total: ~256k parÃ¢metros treinÃ¡veis
```

### Arquitetura Simples mas Eficaz

```
INPUT (120x160x3)
    â†“
[Bloco Conv 1] â†’ 32 filtros â†’ MaxPool â†’ Dropout(0.25)
    â†“
[Bloco Conv 2] â†’ 64 filtros â†’ MaxPool â†’ Dropout(0.25)
    â†“
[Bloco Conv 3] â†’ 128 filtros â†’ MaxPool â†’ Dropout(0.30)
    â†“
Flatten â†’ Dense(256) â†’ Dropout(0.5)
    â†“
OUTPUT: Dense(8, sigmoid)
```

**CaracterÃ­sticas:**
- Totalmente treinÃ¡vel desde zero
- ~256k parÃ¢metros
- Boa baseline para comparaÃ§Ã£o
- RÃ¡pido para treinar

**Vantagem:** Adaptado especificamente para garrafas

---

## ğŸ“ Fundamentos MatemÃ¡ticos: ResNet (Residual Networks)

### O Problema do Vanishing Gradient

Em redes muito profundas, gradientes diminuem exponencialmente durante backpropagation:

```
âˆ‚L/âˆ‚Wâ‚ = âˆ‚L/âˆ‚Wâ‚™ Â· âˆ‚Wâ‚™/âˆ‚Wâ‚™â‚‹â‚ Â· ... Â· âˆ‚Wâ‚‚/âˆ‚Wâ‚

Se cada termo < 1 â†’ produto â†’ 0 (gradiente desaparece)
```

**ConsequÃªncia:** Camadas iniciais nÃ£o aprendem, rede profunda performa pior que rasa.

### A SoluÃ§Ã£o: ConexÃµes Residuais (Skip Connections)

**Ideia revolucionÃ¡ria:** Ao invÃ©s de aprender H(x), aprenda F(x) = H(x) - x

```
Bloco Tradicional:
  x â†’ [Conv] â†’ [ReLU] â†’ [Conv] â†’ H(x)

Bloco Residual:
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                    â”‚
  x â†’  â”‚  [Convâ†’ReLUâ†’Conv]  â”‚  â†’  F(x) + x  â†’ ReLU â†’ saÃ­da
       â”‚         â†“          â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€F(x)â”€â”€â”€â”˜
              (identidade)
```

**Matematicamente:**
```
y = F(x, {Wáµ¢}) + x

Onde:
- x: entrada
- F(x, {Wáµ¢}): transformaÃ§Ã£o residual (camadas conv)
- y = F(x) + x: saÃ­da do bloco
- Identidade: x passa direto (atalho)
```

**Por que funciona?**

1. **Gradiente sempre flui:**
   ```
   âˆ‚y/âˆ‚x = âˆ‚F/âˆ‚x + 1  â†’ sempre tem componente = 1
   ```

2. **Mais fÃ¡cil aprender identidade:**
   - Se F(x) = 0 â†’ y = x (identidade perfeita)
   - Camadas podem "se desligar" se nÃ£o precisarem aprender nada

3. **Permite redes muito profundas:**
   - ResNet50: 50 camadas
   - ResNet152: 152 camadas
   - Sem degradaÃ§Ã£o de performance

### ResNet50: Arquitetura Detalhada

**Estrutura em blocos:**

```
INPUT (224Ã—224Ã—3)
    â†“
[Conv 7Ã—7, stride=2] â†’ (112Ã—112Ã—64)
    â†“
[MaxPool 3Ã—3, stride=2] â†’ (56Ã—56Ã—64)
    â†“
[Bloco Residual Ã—3]  Conv1_x â†’ (56Ã—56Ã—256)
    â†“
[Bloco Residual Ã—4]  Conv2_x â†’ (28Ã—28Ã—512)
    â†“
[Bloco Residual Ã—6]  Conv3_x â†’ (14Ã—14Ã—1024)
    â†“
[Bloco Residual Ã—3]  Conv4_x â†’ (7Ã—7Ã—2048)
    â†“
[GlobalAveragePool] â†’ (2048,)
    â†“
[Dense(1000, softmax)] â†’ ImageNet classes
```

**Bloco Bottleneck (usado em ResNet50):**

```
        x (entrada)
        â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                        â”‚
    â”‚  [Conv 1Ã—1, 64]  â”€â”€â”€â”€â”€â”€â”¼â”€â”€> Reduz dimensionalidade
    â”‚        â†“               â”‚
    â”‚  [Conv 3Ã—3, 64]  â”€â”€â”€â”€â”€â”€â”¼â”€â”€> Processa features
    â”‚        â†“               â”‚
    â”‚  [Conv 1Ã—1, 256] â”€â”€â”€â”€â”€â”€â”¼â”€â”€> Expande dimensionalidade
    â”‚        â”‚               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        F(x) + x
             â”‚
          ReLU
             â†“
        saÃ­da (256 canais)
```

**Matematicamente:**
```
F(x) = Wâ‚ƒÂ·ReLU(Wâ‚‚Â·ReLU(Wâ‚Â·x + bâ‚) + bâ‚‚) + bâ‚ƒ

Onde:
- Wâ‚: Conv 1Ã—1 (reduÃ§Ã£o: 256â†’64 canais)
- Wâ‚‚: Conv 3Ã—3 (processamento: 64â†’64)
- Wâ‚ƒ: Conv 1Ã—1 (expansÃ£o: 64â†’256 canais)

SaÃ­da: y = ReLU(F(x) + x)
```

**Total de parÃ¢metros ResNet50:**
```
~25.6 milhÃµes de parÃ¢metros
```

### Transfer Learning: MatemÃ¡tica da AdaptaÃ§Ã£o

**PrÃ©-treinamento no ImageNet:**
```
f_ImageNet: â„^(224Ã—224Ã—3) â†’ â„^1000

Aprende: Î¸* = argmin Î£ L(f(x_i; Î¸), y_i)
                Î¸    iâˆˆImageNet
```

**AdaptaÃ§Ã£o para Garrafas:**
```
1. Congela base: Î¸_base = Î¸* (fixo)

2. Nova cabeÃ§a: g: â„^2048 â†’ â„^8

3. Treina apenas g:
   Î¸_head* = argmin Î£ L(g(f_base(x_i)), y_i)
              Î¸     iâˆˆGarrafas

4. Modelo final:
   f_garrafas(x) = g(f_base(x; Î¸*); Î¸_head*)
                    â””â”€â”€â”€â”€â”€fixoâ”€â”€â”€â”€â”˜ â””â”€treinaâ”˜
```

**Por que funciona?**

Features de baixo nÃ­vel sÃ£o universais:
- Camadas iniciais: bordas, cores, texturas
- Camadas mÃ©dias: formas, padrÃµes
- Camadas finais: conceitos especÃ­ficos (ImageNet)

**Vantagem:**
```
Garrafas (141 imgs) + ImageNet (1.4M imgs) >> Garrafas sozinhas
```

---

## ğŸš€ Modelo 2: ResNet50 (Transfer Learning)

### Resumo MatemÃ¡tico da AdaptaÃ§Ã£o

**Arquitetura completa para detecÃ§Ã£o de defeitos:**

```
INPUT: X âˆˆ â„^(120Ã—160Ã—3)
   â†“
[Resize para 224Ã—224] â†’ X' âˆˆ â„^(224Ã—224Ã—3)
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ResNet50 Base (CONGELADA)                â”‚
â”‚ - 49 camadas convolucionais              â”‚
â”‚ - 16 blocos residuais                    â”‚
â”‚ - Pesos prÃ©-treinados: Î¸* (ImageNet)    â”‚
â”‚                                          â”‚
â”‚ f_base: â„^(224Ã—224Ã—3) â†’ â„^(7Ã—7Ã—2048)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
[GlobalAveragePooling2D]
   â†“
X_pool âˆˆ â„^2048  (vetor de features)
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CabeÃ§a Customizada (TREINÃVEL)          â”‚
â”‚                                          â”‚
â”‚ Dense(256): h = ReLU(Wâ‚Â·X_pool + bâ‚)     â”‚
â”‚            h âˆˆ â„^256                     â”‚
â”‚    â†“                                     â”‚
â”‚ Dropout(0.5): h' = Dropout(h, p=0.5)     â”‚
â”‚    â†“                                     â”‚
â”‚ Dense(8): Å· = Ïƒ(Wâ‚‚Â·h' + bâ‚‚)              â”‚
â”‚          Å· âˆˆ [0,1]^8                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
OUTPUT: Probabilidades de 8 defeitos
```

**ParÃ¢metros treinÃ¡veis:**
```
GlobalAvgPool: 0 parÃ¢metros
Dense(256): 2048Ã—256 + 256 = 524,544 parÃ¢metros
Dense(8): 256Ã—8 + 8 = 2,056 parÃ¢metros
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total treinÃ¡vel: ~527k parÃ¢metros
Total congelado: ~23M parÃ¢metros (ResNet50)
Total geral: ~25M parÃ¢metros
```

**FunÃ§Ã£o de perda (mesma que CNN):**
```
L = -1/N Î£ Î£ [y_ikÂ·log(Å·_ik) + (1-y_ik)Â·log(1-Å·_ik)]
        i k

Mas gradientes apenas fluem pelas camadas treinÃ¡veis:
âˆ‚L/âˆ‚Î¸_base = 0  (congelado)
âˆ‚L/âˆ‚Î¸_head â‰  0  (treinÃ¡vel)
```

**OtimizaÃ§Ã£o (Adam com LR menor):**
```
Î± = 0.0001  (10x menor que CNN custom)

Por quÃª?
- Features prÃ©-treinadas jÃ¡ sÃ£o boas
- Ajuste fino requer passos menores
- Evita "esquecer" conhecimento do ImageNet
```

### Aproveitando Conhecimento PrÃ©-Treinado

```
ResNet50 (ImageNet)
[23M parÃ¢metros CONGELADOS]
    â†“
GlobalAveragePooling2D
    â†“
Dense(256, relu)
    â†“
Dropout(0.5)
    â†“
OUTPUT: Dense(8, sigmoid)
```

**O que Ã© Transfer Learning?**
- Usa rede treinada em milhÃµes de imagens
- Camadas iniciais detectam features genÃ©ricas (bordas, texturas)
- Apenas Ãºltimas camadas sÃ£o retreinadas para defeitos

**Vantagens:**
- Excelente para datasets pequenos
- Aprende rÃ¡pido (pesos prÃ©-treinados)
- Alta precisÃ£o

**Desvantagens:**
- ~25M parÃ¢metros (pesado)
- Mais lento para inferÃªncia

---

## ğŸ“ Fundamentos MatemÃ¡ticos: MobileNetV2

### O Desafio: EficiÃªncia Computacional

**Problema:** CNNs tradicionais sÃ£o muito pesadas para dispositivos mÃ³veis

```
Conv 3Ã—3 tradicional com 128 canais:
Custo: 3Ã—3Ã—128Ã—128 = 147,456 operaÃ§Ãµes por pixel
```

### SoluÃ§Ã£o 1: Depthwise Separable Convolution

**Ideia:** Separar convoluÃ§Ã£o espacial da convoluÃ§Ã£o de canais

#### **Passo 1: Depthwise Convolution**
Aplica filtro separadamente para cada canal:

```
Entrada: X âˆˆ â„^(HÃ—WÃ—C_in)

Para cada canal c:
  Y_c = Conv2D_3Ã—3(X_c)  (filtro independente)

SaÃ­da: Y âˆˆ â„^(HÃ—WÃ—C_in)
```

**Custo computacional:**
```
3Ã—3Ã—C_in (um filtro 3Ã—3 por canal)
```

#### **Passo 2: Pointwise Convolution**
Combina canais usando Conv 1Ã—1:

```
Entrada: Y âˆˆ â„^(HÃ—WÃ—C_in)

Z = Conv2D_1Ã—1(Y)  (C_out filtros)

SaÃ­da: Z âˆˆ â„^(HÃ—WÃ—C_out)
```

**Custo computacional:**
```
1Ã—1Ã—C_inÃ—C_out
```

#### **Economia Total:**

```
Tradicional: 3Ã—3Ã—C_inÃ—C_out = 9Â·C_inÂ·C_out
SeparÃ¡vel: 3Ã—3Ã—C_in + 1Ã—1Ã—C_inÃ—C_out = 9Â·C_in + C_inÂ·C_out

RazÃ£o: (9Â·C_in + C_inÂ·C_out) / (9Â·C_inÂ·C_out)
     = 1/C_out + 1/9
     â‰ˆ 1/9  (se C_out grande)
```

**Resultado: ~8-9x mais eficiente!**

### SoluÃ§Ã£o 2: Inverted Residual Block (MobileNetV2)

**Problema do MobileNetV1:**
- Depthwise conv opera em poucos canais (informaÃ§Ã£o limitada)

**SoluÃ§Ã£o:** Inverted Bottleneck
- Expande canais ANTES de depthwise
- Comprime DEPOIS

#### **Bloco Linear Bottleneck:**

```
        x (tÂ·C canais)
        â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                        â”‚
    â”‚  [Conv 1Ã—1, expand]    â”‚  â†’ ExpansÃ£o (tÃ—C canais)
    â”‚  [tÂ·C = 6Ã—C tÃ­pico]    â”‚     t = expansion factor
    â”‚        â†“               â”‚
    â”‚  [ReLU6]               â”‚  â†’ AtivaÃ§Ã£o
    â”‚        â†“               â”‚
    â”‚  [DepthConv 3Ã—3]       â”‚  â†’ ConvoluÃ§Ã£o espacial
    â”‚        â†“               â”‚
    â”‚  [ReLU6]               â”‚
    â”‚        â†“               â”‚
    â”‚  [Conv 1Ã—1, project]   â”‚  â†’ ProjeÃ§Ã£o (C canais)
    â”‚        â†“               â”‚
    â”‚  [Linear] â† SEM ReLU!  â”‚  â†’ Preserva informaÃ§Ã£o
    â”‚        â”‚               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        F(x) + x  (se stride=1)
             â†“
```

**Matematicamente:**

```
1. ExpansÃ£o:
   Xâ‚ = ReLU6(Conv1Ã—1_expand(x))
   Xâ‚ âˆˆ â„^(HÃ—WÃ—(tÂ·C))

2. Depthwise:
   Xâ‚‚ = ReLU6(DepthConv3Ã—3(Xâ‚))
   Xâ‚‚ âˆˆ â„^(HÃ—WÃ—(tÂ·C))

3. ProjeÃ§Ã£o linear:
   Xâ‚ƒ = Conv1Ã—1_project(Xâ‚‚)  â† Linear, SEM ativaÃ§Ã£o!
   Xâ‚ƒ âˆˆ â„^(HÃ—WÃ—C)

4. Residual (se stride=1 e C_in=C_out):
   y = Xâ‚ƒ + x
```

**Por que Linear (sem ReLU) na projeÃ§Ã£o?**

```
ReLU(x) = max(0, x) â†’ perde informaÃ§Ã£o negativa

Em baixa dimensionalidade: ReLU destrÃ³i muita informaÃ§Ã£o
SoluÃ§Ã£o: ProjeÃ§Ã£o linear preserva toda informaÃ§Ã£o
```

**ReLU6 (ativaÃ§Ã£o limitada):**
```
ReLU6(x) = min(max(0, x), 6)

Vantagens:
- Robustez em precisÃ£o baixa (quantizaÃ§Ã£o)
- Previne valores muito grandes
- Ideal para dispositivos mÃ³veis
```

### MobileNetV2: Arquitetura Completa

```
INPUT (224Ã—224Ã—3)
    â†“
[Conv 3Ã—3, stride=2] â†’ (112Ã—112Ã—32)
    â†“
[Inverted Residual Ã—1, t=1] â†’ (112Ã—112Ã—16)
    â†“
[Inverted Residual Ã—2, t=6] â†’ (56Ã—56Ã—24)
    â†“
[Inverted Residual Ã—3, t=6] â†’ (28Ã—28Ã—32)
    â†“
[Inverted Residual Ã—4, t=6] â†’ (14Ã—14Ã—64)
    â†“
[Inverted Residual Ã—3, t=6] â†’ (14Ã—14Ã—96)
    â†“
[Inverted Residual Ã—3, t=6] â†’ (7Ã—7Ã—160)
    â†“
[Inverted Residual Ã—1, t=6] â†’ (7Ã—7Ã—320)
    â†“
[Conv 1Ã—1] â†’ (7Ã—7Ã—1280)
    â†“
[GlobalAveragePool] â†’ (1280,)
    â†“
[Dense(1000, softmax)] â†’ ImageNet classes
```

**EstatÃ­sticas:**
```
Total de parÃ¢metros: ~3.4M
OperaÃ§Ãµes (MAdds): ~300M
Tamanho: ~14MB

ComparaÃ§Ã£o:
- ResNet50: 25M parÃ¢metros, ~4B MAdds
- MobileNetV2: 3.4M parÃ¢metros, 300M MAdds
â†’ MobileNetV2 Ã© ~13x mais eficiente!
```

### ComparaÃ§Ã£o: ResNet50 vs MobileNetV2

| Aspecto | ResNet50 | MobileNetV2 |
|---------|----------|-------------|
| **Bloco bÃ¡sico** | Bottleneck clÃ¡ssico | Inverted Residual |
| **ExpansÃ£o** | Reduz â†’ Processa â†’ Expande | Expande â†’ Processa â†’ Reduz |
| **ConvoluÃ§Ã£o** | Tradicional 3Ã—3 | Depthwise Separable |
| **AtivaÃ§Ã£o final** | ReLU | Linear (bottleneck) |
| **ParÃ¢metros** | 25M | 3.4M |
| **EficiÃªncia** | Baseline | 8-13x mais eficiente |
| **Uso** | Servidores/GPUs | Dispositivos mÃ³veis |

---

## ğŸ“± Modelo 3: MobileNetV2 (Leve e RÃ¡pido)

### Resumo MatemÃ¡tico da AdaptaÃ§Ã£o

**Arquitetura completa para detecÃ§Ã£o de defeitos:**

```
INPUT: X âˆˆ â„^(120Ã—160Ã—3)
   â†“
[Resize para 224Ã—224] â†’ X' âˆˆ â„^(224Ã—224Ã—3)
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MobileNetV2 Base (CONGELADA)             â”‚
â”‚ - 53 camadas                             â”‚
â”‚ - 17 blocos Inverted Residual            â”‚
â”‚ - Pesos prÃ©-treinados: Î¸* (ImageNet)    â”‚
â”‚ - Depthwise Separable Convolutions      â”‚
â”‚                                          â”‚
â”‚ f_base: â„^(224Ã—224Ã—3) â†’ â„^(7Ã—7Ã—1280)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
[GlobalAveragePooling2D]
   â†“
X_pool âˆˆ â„^1280  (vetor de features)
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CabeÃ§a Customizada (TREINÃVEL)          â”‚
â”‚ [Menor que ResNet para eficiÃªncia]      â”‚
â”‚                                          â”‚
â”‚ Dense(128): h = ReLU(Wâ‚Â·X_pool + bâ‚)     â”‚
â”‚            h âˆˆ â„^128                     â”‚
â”‚    â†“                                     â”‚
â”‚ Dropout(0.4): h' = Dropout(h, p=0.4)     â”‚
â”‚    â†“                                     â”‚
â”‚ Dense(8): Å· = Ïƒ(Wâ‚‚Â·h' + bâ‚‚)              â”‚
â”‚          Å· âˆˆ [0,1]^8                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
OUTPUT: Probabilidades de 8 defeitos
```

**ParÃ¢metros treinÃ¡veis:**
```
GlobalAvgPool: 0 parÃ¢metros
Dense(128): 1280Ã—128 + 128 = 163,968 parÃ¢metros
Dense(8): 128Ã—8 + 8 = 1,032 parÃ¢metros
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total treinÃ¡vel: ~165k parÃ¢metros
Total congelado: ~2.2M parÃ¢metros (MobileNetV2)
Total geral: ~3.4M parÃ¢metros
```

**ComparaÃ§Ã£o de eficiÃªncia:**
```
                 ParÃ¢metros  InferÃªncia  MemÃ³ria
CNN Custom:         256k        RÃ¡pida     Baixa
ResNet50:           25M         Lenta      Alta
MobileNetV2:        3.4M        RÃ¡pida     MÃ©dia

Trade-off MobileNetV2:
âœ“ 7x mais leve que ResNet50
âœ“ Performance prÃ³xima (~95% do ResNet)
âœ“ Ideal para produÃ§Ã£o
```

**OtimizaÃ§Ã£o (mesma que ResNet50):**
```
Î± = 0.0001  (learning rate baixo)
Loss: Binary Cross-Entropy
Optimizer: Adam

Filosofia idÃªntica ao ResNet:
- Features prÃ©-treinadas de qualidade
- Apenas ajuste fino da cabeÃ§a
- Preserva conhecimento do ImageNet
```

### Otimizado para Dispositivos MÃ³veis

```
MobileNetV2 (ImageNet)
[2.2M parÃ¢metros CONGELADOS]
    â†“
GlobalAveragePooling2D
    â†“
Dense(128, relu)  â† Menor que ResNet
    â†“
Dropout(0.4)
    â†“
OUTPUT: Dense(8, sigmoid)
```

**Por que MobileNet?**
- Arquitetura eficiente (depthwise separable convolutions)
- 10x mais leve que ResNet50
- Ideal para implantaÃ§Ã£o em produÃ§Ã£o

**Trade-off:**
- Performance ligeiramente inferior
- Muito mais rÃ¡pido e leve
- Pode rodar em dispositivos embarcados

---

## âš™ï¸ ConfiguraÃ§Ã£o de Treinamento

### HiperparÃ¢metros Principais:

| ParÃ¢metro | CNN Custom | ResNet50/MobileNet |
|-----------|------------|-------------------|
| **Loss** | Binary Crossentropy | Binary Crossentropy |
| **Optimizer** | Adam (lr=0.001) | Adam (lr=0.0001) |
| **AtivaÃ§Ã£o Final** | Sigmoid | Sigmoid |
| **Ã‰pocas MÃ¡ximas** | 100 | 100 |
| **Batch Size** | 16 | 16 |

### Por que Binary Crossentropy?
- Apropriado para classificaÃ§Ã£o multi-label
- Cada classe Ã© tratada independentemente
- Diferente de Categorical Crossentropy (exclusivo)

### Por que Sigmoid (nÃ£o Softmax)?
- Sigmoid: Cada saÃ­da entre 0-1 independentemente
- Softmax: Soma das saÃ­das = 1 (exclusÃ£o mÃºtua)
- Multi-label precisa de prediÃ§Ãµes independentes

---

## ğŸšï¸ Callbacks Inteligentes: Controle AutomÃ¡tico do Treinamento

### O que sÃ£o Callbacks?

**Callbacks** sÃ£o funÃ§Ãµes executadas automaticamente em momentos especÃ­ficos do treinamento:
- InÃ­cio/fim de cada Ã©poca
- InÃ­cio/fim de cada batch
- Durante validaÃ§Ã£o

**Objetivo:** Automatizar decisÃµes de treinamento sem intervenÃ§Ã£o manual

---

### 1. Early Stopping (Parada Antecipada)

#### **ConfiguraÃ§Ã£o:**
```python
EarlyStopping(
    monitor='val_loss',          # MÃ©trica a monitorar
    patience=15,                 # Ã‰pocas sem melhora
    restore_best_weights=True,   # Restaura melhores pesos
    mode='min',                  # Minimizar val_loss
    min_delta=0.0001            # Melhora mÃ­nima significativa
)
```

#### **Como Funciona (MatemÃ¡tica):**

```
Para cada Ã©poca t:
  1. Calcular mÃ©trica: M(t) = val_loss(t)

  2. Comparar com melhor valor histÃ³rico:
     if M(t) < M_best - Î´:  (Î´ = min_delta)
         M_best = M(t)
         contador = 0
         salva_pesos(Î¸_best = Î¸(t))
     else:
         contador += 1

  3. Verificar paciÃªncia:
     if contador >= patience:
         PARA_TREINAMENTO()
         restaura_pesos(Î¸ = Î¸_best)
```

#### **Exemplo Visual:**

```
Ã‰poca | Val_Loss | Melhor | Contador | AÃ§Ã£o
------|----------|--------|----------|------------------
  1   |  0.850   | 0.850  |    0     | Novo melhor âœ“
  2   |  0.720   | 0.720  |    0     | Novo melhor âœ“
  3   |  0.680   | 0.680  |    0     | Novo melhor âœ“
  4   |  0.685   | 0.680  |    1     | Sem melhora
  5   |  0.690   | 0.680  |    2     | Sem melhora
  6   |  0.650   | 0.650  |    0     | Novo melhor âœ“
  ...  |   ...    |  ...   |   ...    | ...
  20  |  0.655   | 0.650  |   13     | Sem melhora
  21  |  0.658   | 0.650  |   14     | Sem melhora
  22  |  0.660   | 0.650  |   15     | PARA! PaciÃªncia esgotada

Restaura pesos da Ã©poca 6 (melhor val_loss = 0.650)
```

#### **BenefÃ­cios:**

1. **Previne Overfitting:**
   ```
   Train_Loss continua caindo â†’ modelo memorizando
   Val_Loss para de cair/sobe â†’ modelo nÃ£o generaliza
   â†’ Early stopping PARA antes do overfitting
   ```

2. **Economiza Tempo:**
   ```
   Sem callback: 100 Ã©pocas Ã— 5 min = 500 min
   Com callback: Para em 45 Ã©pocas = 225 min
   Economia: 55% de tempo!
   ```

3. **Garante Melhor Modelo:**
   - Sempre restaura pesos da Ã©poca com melhor validaÃ§Ã£o
   - NÃ£o precisa monitorar manualmente

#### **Por que patience=15?**
```
Dataset pequeno (141 imagens):
- Alta variÃ¢ncia entre Ã©pocas
- Pode ter flutuaÃ§Ãµes aleatÃ³rias
- Patience alta evita parar prematuramente

Dataset grande:
- Menor variÃ¢ncia
- Patience menor (5-10 Ã©pocas)
```

---

### 2. ReduceLROnPlateau (Ajuste de Learning Rate)

#### **ConfiguraÃ§Ã£o:**
```python
ReduceLROnPlateau(
    monitor='val_loss',    # MÃ©trica a monitorar
    factor=0.5,            # Multiplicador de reduÃ§Ã£o
    patience=7,            # Ã‰pocas sem melhora
    min_lr=1e-7,          # LR mÃ­nimo permitido
    mode='min',            # Minimizar val_loss
    cooldown=0,           # Ã‰pocas de espera apÃ³s reduÃ§Ã£o
    verbose=1             # Imprimir mensagens
)
```

#### **Como Funciona (MatemÃ¡tica):**

```
Para cada Ã©poca t:
  1. Calcular mÃ©trica: M(t) = val_loss(t)

  2. Verificar estagnaÃ§Ã£o:
     if M(t) < M_recent_best - Î´:
         M_recent_best = M(t)
         contador_lr = 0
     else:
         contador_lr += 1

  3. Reduzir learning rate se estagnado:
     if contador_lr >= patience:
         Î±_new = max(Î±_old Ã— factor, min_lr)
         if Î±_new != Î±_old:
             Î± = Î±_new
             contador_lr = 0
             print(f"LR reduzido: {Î±_old} â†’ {Î±_new}")
```

#### **Exemplo Visual:**

```
Ã‰poca | Val_Loss | LR      | Contador | AÃ§Ã£o
------|----------|---------|----------|---------------------
  1   |  0.850   | 0.001   |    0     | InÃ­cio
  5   |  0.680   | 0.001   |    0     | Melhorando
  10  |  0.650   | 0.001   |    0     | Melhorando
  15  |  0.648   | 0.001   |    1     | Estagnando
  20  |  0.647   | 0.001   |    5     | Estagnando
  22  |  0.647   | 0.001   |    7     | LR â†’ 0.0005 (Ã—0.5)
  25  |  0.640   | 0.0005  |    0     | Melhorando (LR menor)
  35  |  0.638   | 0.0005  |    7     | LR â†’ 0.00025 (Ã—0.5)
  45  |  0.636   | 0.00025 |    0     | Melhorando
  60  |  0.635   | 0.00025 |    7     | LR â†’ 0.000125 (Ã—0.5)
```

#### **Por que Funciona?**

**Analogia da Bola em um Vale:**

```
Learning Rate Alto (inÃ­cio):
    â†“ â†“ â†“
   /     \     Pulos grandes â†’ descida rÃ¡pida
  /   â€¢   \   mas impreciso no fundo
 /         \

Learning Rate Baixo (fim):
         â†“
    /       \   Pulos pequenos â†’ encontra
   /    â€¢    \  exatamente o fundo
  /___________\
```

**Matematicamente:**

```
Gradiente descendente: Î¸_new = Î¸_old - Î±Â·âˆ‡L

LR alto (Î± grande):
- Passos grandes
- Converge rÃ¡pido inicialmente
- Oscila prÃ³ximo ao mÃ­nimo

LR baixo (Î± pequeno):
- Passos pequenos
- Converge devagar
- Preciso no mÃ­nimo local
```

#### **Schedule de Learning Rate:**

```
Ã‰poca 1-22:   Î± = 0.001    (exploraÃ§Ã£o rÃ¡pida)
Ã‰poca 23-34:  Î± = 0.0005   (refinamento)
Ã‰poca 35-59:  Î± = 0.00025  (ajuste fino)
Ã‰poca 60+:    Î± = 0.000125 (convergÃªncia precisa)
```

**ReduÃ§Ã£o exponencial:**
```
Î±(n) = Î±â‚€ Ã— factor^n

Exemplo com Î±â‚€=0.001, factor=0.5:
Î±(0) = 0.001
Î±(1) = 0.0005
Î±(2) = 0.00025
Î±(3) = 0.000125
Î±(4) = 0.0000625
...
Î±(âˆ) â‰¥ min_lr = 1e-7
```

#### **BenefÃ­cios:**

1. **ConvergÃªncia Melhor:**
   ```
   LR fixo: Pode nunca alcanÃ§ar Ã³timo (oscila)
   LR adaptativo: Ajusta automaticamente para convergir
   ```

2. **AutomÃ¡tico:**
   ```
   Manual: Testar diferentes LR schedules
   Callback: Ajusta sozinho baseado no progresso
   ```

3. **Previne PlatÃ´s:**
   ```
   Modelo estagnado em mÃ­nimo local â†’ reduz LR
   â†’ Passos menores permitem escapar/refinar
   ```

---

### 3. CombinaÃ§Ã£o: Early Stopping + ReduceLROnPlateau

**EstratÃ©gia de dois nÃ­veis:**

```
ReduceLROnPlateau (patience=7):
    â”œâ”€> Detecta estagnaÃ§Ã£o RÃPIDA
    â””â”€> Tenta resolver reduzindo LR

EarlyStopping (patience=15):
    â”œâ”€> Detecta estagnaÃ§Ã£o PROLONGADA
    â””â”€> Para treinamento se LR reduzido nÃ£o ajudar
```

**Fluxo de decisÃ£o:**

```
                 Ã‰poca t
                    â†“
            Calcular val_loss
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                     â”‚
    Melhorou?              Estagnado?
         â”‚                     â”‚
        Sim                   NÃ£o
         â”‚                     â”‚
    Resetar                Contador++
    contadores                 â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚             â”‚
         â”‚         Contador=7    Contador=15
         â”‚              â”‚             â”‚
         â”‚        Reduz LR       Para treino
         â”‚              â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
                  PrÃ³xima Ã©poca
```

#### **Exemplo Completo:**

```
Ã‰poca | Val_Loss | LR      | Cnt_LR | Cnt_ES | AÃ§Ã£o
------|----------|---------|--------|--------|------------------
  1   |  0.850   | 0.001   |   0    |   0    | InÃ­cio
  10  |  0.650   | 0.001   |   0    |   0    | Melhorando
  15  |  0.648   | 0.001   |   0    |   1    | Estagnando
  20  |  0.647   | 0.001   |   5    |   5    | Estagnando
  22  |  0.647   | 0.001   |   7    |   7    | LRâ†’0.0005 âœ“
  23  |  0.645   | 0.0005  |   0    |   0    | Melhorou! âœ“
  30  |  0.640   | 0.0005  |   0    |   0    | Melhorando
  37  |  0.639   | 0.0005  |   7    |   7    | LRâ†’0.00025 âœ“
  38  |  0.6385  | 0.00025 |   0    |   1    | Leve melhora
  45  |  0.6384  | 0.00025 |   6    |   7    | Estagnando
  46  |  0.6384  | 0.00025 |   7    |   8    | LRâ†’0.000125 âœ“
  47  |  0.6384  | 0.000125|   1    |   9    | Sem melhora
  ...  |   ...    |  ...    |  ...   |  ...   | ...
  61  |  0.6384  | 0.000125|   5    |  15    | PARA! âœ—

Restaura pesos da Ã©poca 38 (melhor val_loss = 0.6385)
```

---

### 4. Por que Esses Callbacks SÃ£o Essenciais?

#### **Sem Callbacks:**
```python
# CÃ³digo manual (trabalhoso e propenso a erros)
best_loss = float('inf')
patience_counter = 0
lr = 0.001

for epoch in range(100):
    train()
    val_loss = validate()

    # LÃ³gica manual complexa
    if val_loss < best_loss - 0.0001:
        best_loss = val_loss
        save_weights()
        patience_counter = 0
    else:
        patience_counter += 1
        if patience_counter >= 7:
            lr *= 0.5
            if patience_counter >= 15:
                break
```

#### **Com Callbacks:**
```python
# Limpo, automÃ¡tico, testado
callbacks = [
    EarlyStopping(patience=15, restore_best_weights=True),
    ReduceLROnPlateau(factor=0.5, patience=7)
]

model.fit(X, y, validation_data=(X_val, y_val),
          epochs=100, callbacks=callbacks)
```

**Vantagens:**
âœ… CÃ³digo limpo e legÃ­vel
âœ… Testado por milhÃµes de usuÃ¡rios
âœ… Sem bugs de implementaÃ§Ã£o
âœ… FÃ¡cil de ajustar hiperparÃ¢metros
âœ… Integrado ao TensorFlow/Keras

---

## ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o

### MÃ©tricas Multi-Label EspecÃ­ficas:

**1. Accuracy (AcurÃ¡cia)**
- Porcentagem de prediÃ§Ãµes totalmente corretas
- MÃ©trica bÃ¡sica de performance

**2. AUC (Area Under Curve)**
- Ãrea sob curva ROC
- Robusta para classes desbalanceadas
- **MÃ©trica principal para comparaÃ§Ã£o**
- Varia de 0 a 1 (quanto maior, melhor)

**3. Hamming Loss**
- FraÃ§Ã£o de labels incorretas
- EspecÃ­fico para multi-label
- Quanto menor, melhor
- Exemplo: 2 erros em 8 labels = 0.25

**4. Precision & Recall (por classe)**
- Precision: Das prediÃ§Ãµes positivas, quantas estÃ£o corretas?
- Recall: Dos defeitos reais, quantos foram detectados?

---

## ğŸ” AnÃ¡lise ExploratÃ³ria dos Dados

### Insights Descobertos:

**DistribuiÃ§Ã£o de Defeitos:**
- Classes desbalanceadas (alguns defeitos mais raros)
- Necessidade de mÃ©tricas robustas (AUC)

**Defeitos por Garrafa:**
- MÃ©dia de defeitos por imagem
- Algumas garrafas sem defeitos
- Outras com mÃºltiplos defeitos simultÃ¢neos

**VisualizaÃ§Ãµes:**
- Amostras de cada tipo de defeito
- GrÃ¡ficos de distribuiÃ§Ã£o
- Matriz de co-ocorrÃªncia de defeitos

> **ImportÃ¢ncia:** Entender dados antes de modelar

---

## ğŸ† ComparaÃ§Ã£o dos Modelos

### Tabela Comparativa:

| Modelo | ParÃ¢metros | AUC | Hamming Loss | Velocidade | Uso |
|--------|------------|-----|--------------|------------|-----|
| **CNN Custom** | 256k | â­â­â­ | MÃ©dio | âš¡âš¡âš¡ | Baseline/Prototipagem |
| **ResNet50** | 25M | â­â­â­â­â­ | Menor | âš¡ | Alta precisÃ£o |
| **MobileNetV2** | 3M | â­â­â­â­ | Baixo | âš¡âš¡âš¡ | ProduÃ§Ã£o/Embarcados |

### RecomendaÃ§Ãµes:

**Para LaboratÃ³rio/Pesquisa:** ResNet50
- MÃ¡xima precisÃ£o
- Recursos computacionais disponÃ­veis

**Para ProduÃ§Ã£o/Linha de FabricaÃ§Ã£o:** MobileNetV2
- Ã“timo balanÃ§o precisÃ£o/velocidade
- Pode rodar em hardware limitado
- Custo-benefÃ­cio superior

**Para Prototipagem RÃ¡pida:** CNN Custom
- RÃ¡pido para treinar e ajustar
- Entender viabilidade do problema

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Bibliotecas Utilizadas:

**Deep Learning:**
- `TensorFlow/Keras` - Framework principal
- `keras.applications` - Modelos prÃ©-treinados
- `keras.callbacks` - Controle de treinamento

**Processamento de Dados:**
- `NumPy` - OperaÃ§Ãµes matriciais
- `Pandas` - ManipulaÃ§Ã£o de dataframes
- `PIL` - Processamento de imagens

**AnÃ¡lise e VisualizaÃ§Ã£o:**
- `Matplotlib` - GrÃ¡ficos
- `Seaborn` - VisualizaÃ§Ãµes estatÃ­sticas
- `scikit-learn` - MÃ©tricas e divisÃ£o de dados

---

## âœ¨ Destaques TÃ©cnicos

### DecisÃµes Importantes de Projeto:

**1. Multi-Label em vez de Multi-Class**
- Permite detecÃ§Ã£o de mÃºltiplos defeitos
- Mais realista para inspeÃ§Ã£o industrial
- Sigmoid + Binary Crossentropy

**2. Transfer Learning**
- Compensa dataset pequeno (141 imagens)
- Aproveita conhecimento de milhÃµes de imagens
- Base congelada, apenas cabeÃ§a treinÃ¡vel

**3. AdaptaÃ§Ãµes EspecÃ­ficas para Garrafas**
- Sem flip horizontal (mantÃ©m orientaÃ§Ã£o)
- RotaÃ§Ã£o limitada (garrafas sÃ£o verticais)
- Augmentation controlado

**4. Data Augmentation Essencial**
- Aumenta dataset artificialmente
- Previne overfitting
- Melhora generalizaÃ§Ã£o

---

## ğŸ¯ Resultados e ConclusÃµes

### Pontos Fortes do Sistema:

âœ… Detecta mÃºltiplos defeitos simultÃ¢neos
âœ… TrÃªs opÃ§Ãµes de modelo (precisÃ£o vs. velocidade)
âœ… Robusto a variaÃ§Ãµes de iluminaÃ§Ã£o e posiÃ§Ã£o
âœ… Transfer Learning eficaz para dataset pequeno
âœ… MÃ©tricas adequadas para avaliaÃ§Ã£o multi-label

### LimitaÃ§Ãµes:

âš ï¸ Dataset pequeno (141 imagens)
âš ï¸ PossÃ­vel bias em classes raras
âš ï¸ Depende de qualidade das imagens de entrada

### PrÃ³ximos Passos:

1. **Coletar mais dados** - Expandir dataset
2. **Fine-tuning** - Destravar camadas da base
3. **Ensemble** - Combinar prediÃ§Ãµes dos 3 modelos
4. **Threshold Optimization** - Ajustar por classe
5. **Deploy** - Integrar em linha de produÃ§Ã£o

---

## ğŸ’¡ AplicaÃ§Ãµes PrÃ¡ticas

### CenÃ¡rios de Uso:

**1. Linha de ProduÃ§Ã£o**
- InspeÃ§Ã£o automÃ¡tica 24/7
- ReduÃ§Ã£o de falhas humanas
- Aumento de throughput

**2. Controle de Qualidade**
- Rastreamento de defeitos por lote
- AnÃ¡lise de tendÃªncias
- Melhoria contÃ­nua de processos

**3. Alertas em Tempo Real**
- NotificaÃ§Ã£o imediata de defeitos
- IntervenÃ§Ã£o rÃ¡pida
- ReduÃ§Ã£o de desperdÃ­cio

**4. RelatÃ³rios Automatizados**
- EstatÃ­sticas de produÃ§Ã£o
- KPIs de qualidade
- Auditoria e compliance

---

## ğŸ“š ReferÃªncias e Recursos

### Arquiteturas Utilizadas:

- **ResNet50:** He et al., 2015 - "Deep Residual Learning for Image Recognition"
- **MobileNetV2:** Sandler et al., 2018 - "Inverted Residuals and Linear Bottlenecks"

### Conceitos Aplicados:

- Transfer Learning
- Data Augmentation
- Multi-Label Classification
- Binary Cross-Entropy Loss
- Early Stopping & Learning Rate Scheduling

### Dataset:

- Ground Truth: `bottles_ground_truth.csv`
- Imagens reais de linha de produÃ§Ã£o
- 8 categorias de defeitos anotadas

---

## ğŸ™ Obrigado!

### Resumo Final:

Este projeto demonstra como **Deep Learning** pode ser aplicado eficazmente em **inspeÃ§Ã£o industrial**, mesmo com **datasets limitados**, usando tÃ©cnicas como:

- ğŸ”„ Data Augmentation
- ğŸ§  Transfer Learning
- ğŸ“Š ClassificaÃ§Ã£o Multi-Label
- âš–ï¸ BalanÃ§o entre precisÃ£o e eficiÃªncia

**Resultado:** Sistema robusto e prÃ¡tico para detecÃ§Ã£o automÃ¡tica de defeitos em garrafas

---

### Contato e Perguntas

**DocumentaÃ§Ã£o Completa:** `Deteccao_Defeitos_Garrafas_CocaCola.ipynb`

**Modelos DisponÃ­veis:**
- CNN Custom (baseline)
- ResNet50 (mÃ¡xima precisÃ£o)
- MobileNetV2 (produÃ§Ã£o)

---
